{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_03_echo_cancelling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbqkmaY9RA-z"
      },
      "source": [
        "# 第7回 その3: エコーキャンセリング\n",
        "NLMSアルゴリズムによるエコーキャンセリングのデモンストレーションです。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ステップ0: Google Driveのマウントと作業フォルダへの移動  \n",
        "Google Drive に配置したデータを読み込むための準備です。  \n",
        "詳細については第二回の 02_01_graph.ipynb を参照してください。  \n",
        "\n",
        "ここでは\"マイドライブ/情報管理/07\"を作業フォルダとします。 "
      ],
      "metadata": {
        "id": "U1Pj2rcbB4Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# フォルダの移動には\"%cd\"を使用します。\n",
        "# 作業フォルダへ移動\n",
        "%cd /content/drive/'My Drive'/情報管理/07/\n",
        "# 現在のフォルダの中身を表示\n",
        "%ls"
      ],
      "metadata": {
        "id": "He0jeP7VB-Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`echo_mixed_input.wav`と`reference.wav`というデータが表示されていることを確認してください。"
      ],
      "metadata": {
        "id": "cQkYRZgwCG5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "必要なライブラリをインポートしておきます。"
      ],
      "metadata": {
        "id": "rI8CFGCPdjHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wave as wave\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "XsWs_X_ZdiV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ステップ1: マイク収録信号（音声＋雑音）とスピーカ再生音データの読み込み  \n",
        "まずマイクで収録された音声信号 `echo_mixed_input.wav` を読み込みます。  "
      ],
      "metadata": {
        "id": "9GaSNEjNROXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wav_file = 'echo_mixed_input.wav'\n",
        "with wave.open(wav_file, 'rb') as wav:\n",
        "  # サンプリング周波数 [Hz] を取得\n",
        "  sampling_frequency = wav.getframerate()\n",
        "  # その他の情報（ファイルサイズ等，書き込み時に必要）を取得\n",
        "  wav_params = wav.getparams()\n",
        "  # wavデータを読み込む\n",
        "  input_data = wav.readframes(wav.getnframes())\n",
        "  # 読み込んだデータはバイナリ値(16bit short型)なので，numpy array型の数値ベクトル(32bit float型)に変換する\n",
        "  input_data = np.frombuffer(input_data, dtype=np.int16).astype(np.float32)\n",
        "\n",
        "# データをプロット\n",
        "plt.figure(figsize=(10,5))\n",
        "x = np.arange(np.size(input_data)) / sampling_frequency # 横軸データ\n",
        "plt.plot(x, input_data)\n",
        "plt.xlabel('Time [second]')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()\n",
        "\n",
        "import IPython.display\n",
        "IPython.display.display(IPython.display.Audio('echo_mixed_input.wav'))"
      ],
      "metadata": {
        "id": "-62Mslb7SRvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "続いて，スピーカから再生させる音楽データ（ここでは**参照信号**(**reference**)と呼びます）を読み込みます。  \n",
        "（再生している音楽は ヴィヴァルディ「四季」より「冬」です。）"
      ],
      "metadata": {
        "id": "gAwznJhVTMjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ref_file = 'reference.wav'\n",
        "with wave.open(ref_file, 'rb') as ref:\n",
        "  # （サンプリング周波数やその他の情報の取得は省略する。）\n",
        "  # wavデータを読み込む\n",
        "  reference_data = ref.readframes(ref.getnframes())\n",
        "  # 読み込んだデータはバイナリ値(16bit short型)なので，numpy array型の数値ベクトル(32bit float型)に変換する\n",
        "  reference_data = np.frombuffer(reference_data, dtype=np.int16).astype(np.float32)\n",
        "\n",
        "# データをプロット\n",
        "plt.figure(figsize=(10,5))\n",
        "x = np.arange(np.size(reference_data)) / sampling_frequency # 横軸データ\n",
        "plt.plot(x, reference_data)\n",
        "plt.xlabel('Time [second]')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()\n",
        "\n",
        "IPython.display.display(IPython.display.Audio('reference.wav'))"
      ],
      "metadata": {
        "id": "TMmz2_Y-Tayw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1DmeW6oRs8r"
      },
      "source": [
        "## ステップ2: NLMSアルゴリズム\n",
        "NLMSアルゴリズムの式を以下にまとめます。  \n",
        "$y[n] = \\sum_{k=0}^{K-1}\\hat{h}_{\\rm old}[k]x[n-k]$  \n",
        "$e[n] = z[n] - y[n]$  \n",
        "$\\hat{h}_{\\rm new} = \\hat{h}_{\\rm old} + \\frac{\\mu}{\\sum_{k=0}^{K-1}(x[n-k])^{2}+\\epsilon}e[n]x[n-k]$  \n",
        "\n",
        "$n$，$k$は時刻を表す記号  \n",
        "$x[n]$はスピーカから再生する信号（参照信号，`reference_data`）  \n",
        "$\\hat{h}_{\\rm old}[k]$，$\\hat{h}_{\\rm new}[k]$は推定したインパルス応答（`estimated_rir`，長さ $K$）。oldは更新前，newは更新後。  \n",
        "$y[n]$は推定したマイク入力音（`estimated_echo`）  \n",
        "$z[n]$は実際のマイク入力音（`input_data`）  \n",
        "$e[n]$はエコーキャンセリングによる消し残り（`error`，`output_data`）  \n",
        "$\\mu$はNLMSアルゴリズムにおける学習率（`myu`）  \n",
        "$\\epsilon$はゼロ割を防ぐための小さい値（1e-10）\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "事前に設定すべきパラメータ（機械学習分野において，ハイパーパラメータと呼ばれます）を設定します。"
      ],
      "metadata": {
        "id": "Fb14uaFmYUCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 想定するインパルス応答の長さ\n",
        "K = 1024\n",
        "\n",
        "# インパルス応答の学習率  \n",
        "myu = 1.0\n",
        "\n",
        "# インパルス応答の学習を止める時刻\n",
        "stop_update_time = 10.0\n",
        "\n",
        "# ゼロ割防止のための小さい値\n",
        "eps = 1e-10"
      ],
      "metadata": {
        "id": "Aq7K4NCAYg6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`stop_update_time = 10.0` はインパルス応答の学習を止める時刻です。  \n",
        "言い換えると，この設定では，最初の10秒間の音声データを使ってインパルス応答の学習を行います。  \n",
        "\n",
        "以下に，NLMSアルゴリズムを実装します。"
      ],
      "metadata": {
        "id": "U6hhfYNAZfgW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# マイク収録音(input_data)の長さ\n",
        "N = np.size(input_data)\n",
        "# 推定されたインパルス応答\n",
        "estimated_rir = np.zeros(K)\n",
        "# エコーキャンセリング後の信号\n",
        "output_data = np.zeros(N)\n",
        "\n",
        "for n in range(N):\n",
        "  if n-K+1 < 0:\n",
        "    # n-K+1<0の場合，以降の処理においてベクトルの\n",
        "    # インデクスが負になるため，この場合は畳み込みをしない。\n",
        "    output_data[n] = input_data[n]\n",
        "  else:\n",
        "    #\n",
        "    # NLMSアルゴリズムによるエコーキャンセリングを実行する。\n",
        "    #\n",
        "\n",
        "    # 現在の推定インパルス応答と参照信号の畳み込みを行い，\n",
        "    # スピーカの収録信号（エコー）を推定する。\n",
        "    # 畳み込みについては07_02_convolve_rir.ipynbを参照\n",
        "    reference_part = reference_data[n-K+1:n+1]\n",
        "    reference_rev = np.flip(reference_part)\n",
        "    estimated_echo = np.dot(estimated_rir, reference_rev)\n",
        "\n",
        "    # 入力信号からエコー信号を引くことで、エコーを除去する。\n",
        "    # このとき、減算結果がエコーの消し残り(error)である。\n",
        "    output_data[n] = input_data[n] - estimated_echo\n",
        "    error = output_data[n]\n",
        "\n",
        "    # 正規化項(参照信号のパワー)を求める。  \n",
        "    norm = np.sum(reference_rev**2) + eps\n",
        "\n",
        "    # インパルス応答の更新を止める時間(stop_update_time * sampling_rate)に\n",
        "    # 達していない場合はインパルス応答の推定値を更新する\n",
        "    if n < stop_update_time * sampling_frequency:\n",
        "      estimated_rir += (myu / norm) * error * reference_rev\n"
      ],
      "metadata": {
        "id": "JmuHNA7baAZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "実行結果を出力します。  "
      ],
      "metadata": {
        "id": "fEIqInOydnAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_file = 'output.wav'\n",
        "with wave.open(out_file, 'wb') as out:\n",
        "  # 音声データの情報（wav_params）をセット\n",
        "  out.setparams(wav_params)\n",
        "  # numpy array型(32bit float)のデータをバイナリデータ（16bit short）に変換\n",
        "  out_binary_data = output_data.astype(np.int16).tobytes()\n",
        "  # データを書き込む\n",
        "  out.writeframes(out_binary_data)\n",
        "\n",
        "# データをプロット\n",
        "plt.figure(figsize=(10,5))\n",
        "x = np.arange(np.size(output_data)) / sampling_frequency # 横軸データ\n",
        "plt.plot(x, output_data)\n",
        "plt.xlabel('Time [second]')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()\n",
        "\n",
        "import IPython.display\n",
        "IPython.display.display(IPython.display.Audio('output.wav'))"
      ],
      "metadata": {
        "id": "xDYJEBiMbkD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "音楽が抑圧されて，音声が聞き取りやすくなっていることが分かります。\n",
        "最初の時刻は消し残りが大きく，時間がたつにつれて雑音除去の効果が強まっていくのは，最初の時刻ではインパルス応答が正確に推定できておらず，勾配降下法によって更新が進むにつれてインパルス応答の推定が正確になっているためです。"
      ],
      "metadata": {
        "id": "eGAGImiimodz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "推定（学習）したインパルス応答を出力します。"
      ],
      "metadata": {
        "id": "gFb2t9sTekMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データをプロット\n",
        "plt.figure(figsize=(10,5))\n",
        "x_r = np.arange(np.size(estimated_rir)) / sampling_frequency # 横軸データ\n",
        "plt.plot(x_r, estimated_rir)\n",
        "plt.xlabel('Time [second]')\n",
        "plt.ylabel('Impulse response')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RaKNMQGVdQCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "以上がNLMSエコーキャンセリングのデモンストレーションです。  \n",
        "今回はインパルス応答が時間変化せず，かつ最初の10秒間において音声が入っていないという理想的な環境をシミュレーションしたデータを用いたため，きれいに雑音除去ができました。  \n",
        "しかし現実世界はインパルス応答が部屋の環境変化（部屋に置いてある物体が移動，空気の流れ，気温，など）によって時々刻々と変化するなど，今回のシミュレーションデータとは異なる点が沢山あるため，エコーキャンセリングは容易ではありません。  \n",
        "レポート課題でこの難しさについて触れてみてください。"
      ],
      "metadata": {
        "id": "cSK7Jovsez9T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H2cRy1aXkdkr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}