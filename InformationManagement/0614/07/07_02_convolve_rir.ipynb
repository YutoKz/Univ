{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_02_convolve_rir.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbqkmaY9RA-z"
      },
      "source": [
        "# 第7回 その2: 畳み込みと残響\n",
        "ここでは畳み込みの実装コードを紹介し，音声とインパルス応答の畳み込みによる残響音声のデモンストレーションを行います。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ステップ0: Google Driveのマウントと作業フォルダへの移動  \n",
        "Google Drive に配置したデータを読み込むための準備です。  \n",
        "詳細については第二回の 02_01_graph.ipynb を参照してください。  \n",
        "\n",
        "ここでは\"マイドライブ/情報管理/07\"を作業フォルダとします。 "
      ],
      "metadata": {
        "id": "U1Pj2rcbB4Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# フォルダの移動には\"%cd\"を使用します。\n",
        "# 作業フォルダへ移動\n",
        "%cd /content/drive/'My Drive'/情報管理/07/\n",
        "# 現在のフォルダの中身を表示\n",
        "%ls"
      ],
      "metadata": {
        "id": "He0jeP7VB-Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`input.wav`，`rir_310.wav`，`rir_1000.wav`，`rir_hall.wav`というデータが表示されていることを確認してください。"
      ],
      "metadata": {
        "id": "cQkYRZgwCG5J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "必要なライブラリをインポートしておきます。"
      ],
      "metadata": {
        "id": "rI8CFGCPdjHJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import wave as wave\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "XsWs_X_ZdiV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1DmeW6oRs8r"
      },
      "source": [
        "## ステップ1: 畳み込み\n",
        "畳み込みは以下の式で定義されます。  \n",
        "$z[n] = \\sum_{k=0}^{K-1}h[k]x[n-k]$  \n",
        "$n$，$k$ はそれぞれ時刻を表す記号です。  \n",
        "$x[n]$ は畳み込まれる前の源信号です。  \n",
        "$h[k]$ は畳み込む信号（インパルス応答）で，$k=0,\\dots,K-1$です。  \n",
        "$z[n]$ は $x$ に $h$ が畳み込まれた結果の信号です。  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "以下に $x$ と $h$ の畳み込みを行う関数を定義します。"
      ],
      "metadata": {
        "id": "J-P3BGUmb30S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convolve(x, h):\n",
        "  N = np.size(x) # ベクトル x の長さ\n",
        "  K = np.size(h) # ベクトル h の長さ\n",
        "  z = np.zeros(N) # 畳み込み結果のベクトル（長さN）\n",
        "  \n",
        "  for n in range(N):\n",
        "    if n-K+1 < 0:\n",
        "      # x[n-k+1]のインデクスが0以下になる場合は畳み込みをしない。\n",
        "      z[n] = x[n]\n",
        "    else:\n",
        "      # nからK個分前の要素(n-K+1)からn番目までの要素(n+1)を取り出す\n",
        "      x_part = x[n-K+1 : n+1]\n",
        "      # 取り出したベクトルを逆順に並び替える\n",
        "      x_rev = np.flip(x_part)\n",
        "      # 逆順に並び替えたベクトルと h の内積を計算\n",
        "      z[n] = np.dot(h, x_rev)\n",
        "  \n",
        "  return z"
      ],
      "metadata": {
        "id": "xDYJEBiMbkD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "定義した関数を使って，$x = [0, 1, 2, 3, 4, 5]$，$h = [0.2, 0.3, 0.4]$として畳み込みを実行してみます。  "
      ],
      "metadata": {
        "id": "gFb2t9sTekMV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = np.array([0,1,2,3,4,5])\n",
        "h = np.array([0.2, 0.3, 0.4])\n",
        "# 畳み込み実行\n",
        "z = convolve(x, h)\n",
        "print('z = x*h = ' + str(z))"
      ],
      "metadata": {
        "id": "RaKNMQGVdQCu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "$z = [0.0, 1.0, 0.7, 1.6, 2.5, 3.4]$となります。  \n",
        "\n",
        "[補足]  \n",
        "最初の２要素（$0.0, 1.0$）は $n-K+1 < 0$ となるため，畳み込みを実行していません。実はこのエラー処理はかなり雑で，本来は $n-K+1 < 0$ となる場合は $K$ を $K - n-1$に置き換えるなどの処理をするのが正しいです。ですが，ここでは簡単な実装を採用しています。"
      ],
      "metadata": {
        "id": "cSK7Jovsez9T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ステップ2: インパルス応答の畳み込みと残響  \n",
        "上で定義した畳み込み関数を使って，実際に音声とインパルス応答を畳み込んでみましょう。  \n",
        "まずは音声データ`input.wav`を読み込みます。"
      ],
      "metadata": {
        "id": "Ao0dhiQrgSKP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkibCXvsRv-8"
      },
      "source": [
        "wav_file = 'input.wav'\n",
        "with wave.open(wav_file, 'rb') as wav:\n",
        "  # サンプリング周波数 [Hz] を取得\n",
        "  sampling_frequency = wav.getframerate()\n",
        "  # その他の情報（ファイルサイズ等，書き込み時に必要）を取得\n",
        "  wav_params = wav.getparams()\n",
        "  # wavデータを読み込む\n",
        "  input_data = wav.readframes(wav.getnframes())\n",
        "  # 読み込んだデータはバイナリ値(16bit short型)なので，numpy array型の数値ベクトル(32bit float型)に変換する\n",
        "  input_data = np.frombuffer(input_data, dtype=np.int16).astype(np.float32)\n",
        "\n",
        "# データをプロット\n",
        "plt.figure(figsize=(10,5))\n",
        "x = np.arange(np.size(input_data)) / sampling_frequency # 横軸データ\n",
        "plt.plot(x, input_data)\n",
        "plt.xlabel('Time [second]')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "続いてインパルス応答データ `rir_310.wav` も読み込みます。  \n",
        "（インパルス応答は音声ではありませんが，ここでは処理を簡単にするため，音声と同じwav形式のファイルで作成しています。）  \n",
        "また，インパルス応答は最大値が1.0になるように正規化しておきます。"
      ],
      "metadata": {
        "id": "s2_e295NgsWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rir_file = 'rir_310.wav'\n",
        "with wave.open(rir_file, 'rb') as rir:\n",
        "  # （サンプリング周波数やその他の情報の取得は省略する。）\n",
        "  # wavデータを読み込む\n",
        "  rir_data = rir.readframes(rir.getnframes())\n",
        "  # 読み込んだデータはバイナリ値(16bit short型)なので，numpy array型の数値ベクトル(32bit float型)に変換する\n",
        "  rir_data = np.frombuffer(rir_data, dtype=np.int16).astype(np.float32)\n",
        "\n",
        "  # 最大値が1.0になるように正規化\n",
        "  rir_data = 1.0 * rir_data / 32768\n",
        "\n",
        "# データをプロット\n",
        "plt.figure(figsize=(10,5))\n",
        "x_r = np.arange(np.size(rir_data)) / sampling_frequency # 横軸データ\n",
        "plt.plot(x_r, rir_data)\n",
        "plt.xlabel('Time [second]')\n",
        "plt.ylabel('Impulse response')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jCbVtWo9g-It"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "読み込んだ音声データ `input_data` と インパルス応答 `rir_data` を畳み込みます。"
      ],
      "metadata": {
        "id": "6t7sfIoDEDiI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBozvGsXm0S3"
      },
      "source": [
        "# インパルス応答との畳み込みを実行\n",
        "output_data = convolve(input_data, rir_data)\n",
        "\n",
        "# データをプロット\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(x, input_data, label='input')\n",
        "plt.xlabel('Time [second]')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(x, output_data, label='output')\n",
        "plt.xlabel('Time [second]')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "畳み込んだ結果を`output.wav`というファイル名で書き込み，元の音声信号と聞き比べてみましょう。  \n",
        "書き込むとき，`output_data` は float型になっているので，  \n",
        "`output_data = output_data.astype(np.int16)`  \n",
        "として short 型に変更してから`tobytes`でバイナリデータに変換している点に注意してください。  \n",
        "（これをしないと出力したwavデータはめちゃくちゃな音になります。）"
      ],
      "metadata": {
        "id": "dGGd9LIjEoaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out_file = 'output.wav'\n",
        "with wave.open(out_file, 'wb') as out:\n",
        "  # 音声データの情報（wav_params）をセット\n",
        "  out.setparams(wav_params)\n",
        "  # numpy array型(32bit float)のデータをバイナリデータ（16bit short）に変換\n",
        "  out_binary_data = output_data.astype(np.int16).tobytes()\n",
        "  # データを書き込む\n",
        "  out.writeframes(out_binary_data)\n",
        "\n",
        "import IPython.display\n",
        "print('input.wav')\n",
        "IPython.display.display(IPython.display.Audio('input.wav'))\n",
        "print('output.wav')\n",
        "IPython.display.display(IPython.display.Audio('output.wav'))"
      ],
      "metadata": {
        "id": "dVgPsOtYMC7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "両者を聞き比べると，畳み込んだ音声はややくぐもった音声に聞こえるのが確認できるはずです。  \n",
        "このように，部屋の反射によって過去の音声が畳み込まれる現象のことを<font color='red'>**残響**</font>と呼びます。"
      ],
      "metadata": {
        "id": "TFpYpEgrjdcK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ステップ3: インパルス応答の違いによる残響音声の変化  \n",
        "他のインパルス応答`rir_1000.wav`や`rir_hall.wav`での畳み込みも試してみましょう。  \n",
        "以下は，上記のソースコードを `rir_file`のファイル名を変えてコピペしているだけです。 "
      ],
      "metadata": {
        "id": "BtEb0NY4j67f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rir_file = 'rir_1000.wav'\n",
        "with wave.open(rir_file, 'rb') as rir:\n",
        "  # （サンプリング周波数やその他の情報の取得は省略する。）\n",
        "  # wavデータを読み込む\n",
        "  rir_data = rir.readframes(rir.getnframes())\n",
        "  # 読み込んだデータはバイナリ値(16bit short型)なので，numpy array型の数値ベクトル(32bit float型)に変換する\n",
        "  rir_data = np.frombuffer(rir_data, dtype=np.int16).astype(np.float32)\n",
        "\n",
        "  # 最大値が1.0になるように正規化\n",
        "  rir_data = 1.0 * rir_data / 32768\n",
        "\n",
        "# データをプロット\n",
        "plt.figure(figsize=(10,5))\n",
        "x_r = np.arange(np.size(rir_data)) / sampling_frequency # 横軸データ\n",
        "plt.plot(x_r, rir_data)\n",
        "plt.xlabel('Time [second]')\n",
        "plt.ylabel('Impulse response')\n",
        "plt.show()\n",
        "\n",
        "# インパルス応答との畳み込みを実行\n",
        "output_data = convolve(input_data, rir_data)\n",
        "\n",
        "# データをプロット\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(x, input_data, label='input')\n",
        "plt.xlabel('Time [second]')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(x, output_data, label='output')\n",
        "plt.xlabel('Time [second]')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "out_file = 'output.wav'\n",
        "with wave.open(out_file, 'wb') as out:\n",
        "  # 音声データの情報（wav_params）をセット\n",
        "  out.setparams(wav_params)\n",
        "  # numpy array型(32bit float)のデータをバイナリデータ（16bit short）に変換\n",
        "  out_binary_data = output_data.astype(np.int16).tobytes()\n",
        "  # データを書き込む\n",
        "  out.writeframes(out_binary_data)\n",
        "\n",
        "import IPython.display\n",
        "print('input.wav')\n",
        "IPython.display.display(IPython.display.Audio('input.wav'))\n",
        "print('output.wav')\n",
        "IPython.display.display(IPython.display.Audio('output.wav'))"
      ],
      "metadata": {
        "id": "vQnPZR1DUeYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rir_file = 'rir_hall.wav'\n",
        "with wave.open(rir_file, 'rb') as rir:\n",
        "  # （サンプリング周波数やその他の情報の取得は省略する。）\n",
        "  # wavデータを読み込む\n",
        "  rir_data = rir.readframes(rir.getnframes())\n",
        "  # 読み込んだデータはバイナリ値(16bit short型)なので，numpy array型の数値ベクトル(32bit float型)に変換する\n",
        "  rir_data = np.frombuffer(rir_data, dtype=np.int16).astype(np.float32)\n",
        "\n",
        "  # 最大値が1.0になるように正規化\n",
        "  rir_data = 1.0 * rir_data / 32768\n",
        "\n",
        "# データをプロット\n",
        "plt.figure(figsize=(10,5))\n",
        "x_r = np.arange(np.size(rir_data)) / sampling_frequency # 横軸データ\n",
        "plt.plot(x_r, rir_data)\n",
        "plt.xlabel('Time [second]')\n",
        "plt.ylabel('Impulse response')\n",
        "plt.show()\n",
        "\n",
        "# インパルス応答との畳み込みを実行\n",
        "output_data = convolve(input_data, rir_data)\n",
        "\n",
        "# データをプロット\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(x, input_data, label='input')\n",
        "plt.xlabel('Time [second]')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(x, output_data, label='output')\n",
        "plt.xlabel('Time [second]')\n",
        "plt.ylabel('Amplitude')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "out_file = 'output.wav'\n",
        "with wave.open(out_file, 'wb') as out:\n",
        "  # 音声データの情報（wav_params）をセット\n",
        "  out.setparams(wav_params)\n",
        "  # numpy array型(32bit float)のデータをバイナリデータ（16bit short）に変換\n",
        "  out_binary_data = output_data.astype(np.int16).tobytes()\n",
        "  # データを書き込む\n",
        "  out.writeframes(out_binary_data)\n",
        "\n",
        "import IPython.display\n",
        "print('input.wav')\n",
        "IPython.display.display(IPython.display.Audio('input.wav'))\n",
        "print('output.wav')\n",
        "IPython.display.display(IPython.display.Audio('output.wav'))"
      ],
      "metadata": {
        "id": "xFWYCzv0kO8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "インパルス応答が長くなるにしたがって，残響の影響も大きくなることが確認できたはずです。  \n",
        "ちなみに，`rir_hall.wav`はコンサートホールで収録されたインパルス応答です。  \n",
        "インパルス応答を事前に計測して記録しておくことで，その場で収録したような音声がシミュレーション生成できるということです。"
      ],
      "metadata": {
        "id": "uIqq4j0PkiCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H2cRy1aXkdkr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}