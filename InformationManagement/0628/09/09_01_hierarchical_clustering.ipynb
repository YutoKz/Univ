{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09_01_hierarchical_clustering.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbqkmaY9RA-z"
      },
      "source": [
        "# 第9回: 階層クラスタリング\n",
        "階層クラスタリングを使ってデータの教師無しクラスタリングを行います。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srIl-shURTM2"
      },
      "source": [
        "## ステップ0: Google Driveのマウントと作業フォルダへの移動  \n",
        "Google Drive に配置したデータを読み込むための準備です。  \n",
        "詳細については第二回の 02_01_graph.ipynb を参照してください。  \n",
        "\n",
        "ここでは\"マイドライブ/情報管理/09\"を作業フォルダとします。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf9ghfr_QzT1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# フォルダの移動には\"%cd\"を使用します。\n",
        "# 作業フォルダへ移動\n",
        "%cd /content/drive/'My Drive'/情報管理/09/\n",
        "# 現在のフォルダの中身を表示\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNGpM3FYRiob"
      },
      "source": [
        "`car.csv`というデータが表示されていることを確認してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1DmeW6oRs8r"
      },
      "source": [
        "## ステップ1: データの読み込み\n",
        "まずは必要ライブラリをインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4b4cfHPRXML"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記のライブラリに加えて，japanize_matplotlibと呼ばれるライブラリをインポートします。  \n",
        "これを使うとグラフの作成に日本語を使用することができます。  \n",
        "ただし，google colab.にjapanize_matplotlibはインストールされていないため，\n",
        "`!pip install japanize-matplotlib`というコマンドによりインストールしてからインポートしています。  "
      ],
      "metadata": {
        "id": "V98LvpWmr7J8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install japanize-matplotlib\n",
        "import japanize_matplotlib "
      ],
      "metadata": {
        "id": "y7FKV7mdsASB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF6-hyJ2Sdau"
      },
      "source": [
        "`car.csv` を読み込みます。  \n",
        "このデータは第5回のレポート課題で使用した，車の燃費や車体重量などを記載したデータです。  \n",
        "レポート課題では主成分分析を使って2次元に圧縮していましたが，ここでは簡単のため「燃費」と「排気量」のデータのみを抽出して2次元データとしています。  \n",
        "<font color=red>前回の補足にも述べましたが，クラスタリング自体は3次元以上のデータにも適用可能です。ここでは単にクラスタリング結果を2次元グラフにプロットしたいという理由から，2次元化をしています。</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkibCXvsRv-8"
      },
      "source": [
        "# pandas の関数 read_csv を用いた csvファイル読み込み\n",
        "csv_data = pd.read_csv('car.csv', encoding='SHIFT-JIS')\n",
        "\n",
        "# データの前半部(.headで取得できる)のみ表示\n",
        "display(csv_data.head())\n",
        "\n",
        "# 燃費と排気量のみ抽出した上で，numpy用データ(ndarray型) に変換する。\n",
        "X = csv_data.loc[:, ['燃費','排気量']].to_numpy()\n",
        "\n",
        "# 各サンプルの車体番号をサンプルの名前とする。\n",
        "labels = csv_data.loc[:,'車体番号'].to_list()\n",
        "\n",
        "# データのサンプル数と次元数を得る。\n",
        "(num_samples, num_dimensions) = np.shape(X)\n",
        "print('Nunber of samples: ' + str(num_samples))\n",
        "print('Number of dimensions: ' + str(num_dimensions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glCVWFIRID3y"
      },
      "source": [
        "## ステップ2: データの標準化 \n",
        "燃費(km/L)と排気量(cc)は単位が違います。  \n",
        "排気量の方が値が大きいため，ユークリッド距離を計算すると燃費に比べて排気量の影響が強くなってしまいます。  \n",
        "そのため，標準化を行います。  \n",
        "（標準化については第5回で説明。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Em_IcIDIL6A"
      },
      "source": [
        "# データの標準化\n",
        "X_norm = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "# 二次元データのプロット\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.scatter(X_norm[:,0], X_norm[:,1], color='k')\n",
        "plt.xlabel('燃費（標準化済み）')\n",
        "plt.ylabel('排気量（標準化済み）')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "japanize_matplotlib ライブラリをインポートしているため，横軸と縦軸が日本語表示されています。  \n",
        "（インポートされていない場合，文字化けします。）"
      ],
      "metadata": {
        "id": "o4dHdKANuF1I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12eW3PQc_5Lh"
      },
      "source": [
        "## ステップ3: 階層クラスタリングのためのデータの準備  \n",
        "ここから階層クラスタリングを行います。  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず初期状態として，各サンプルをそれぞれクラスとして扱います。  \n",
        "すなわち「クラス数 = サンプル数」です。  \n",
        "この状態を以下のようにリストを使って定義します。"
      ],
      "metadata": {
        "id": "t35dmcwU6Tlm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# クラスを空のリストとして定義\n",
        "initial_class_list = []\n",
        "\n",
        "# 各サンプルのデータを initial_class_list に追加（append関数）していく\n",
        "for n in range(num_samples):\n",
        "  initial_class_list.append(np.array([X_norm[n]]))\n",
        "\n",
        "print(type(initial_class_list))\n",
        "print(initial_class_list)"
      ],
      "metadata": {
        "id": "SL8-f9fBFhP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "今，各クラスのデータをリスト型（numpyではなく，単なるリスト型。1回目の授業スライドのp.22参照）で定義しました。  \n",
        "リストは「要素数=クラス数」の配列で定義されています。  \n",
        "また，リスト内の各要素は numpy array型で定義されています。  \n",
        "numpy arrayには，そのクラスに属するデータが格納されています。\n",
        "numpy arrayの行数は，そのクラスに属するデータのサンプル数，列数は次元数に相当します。  "
      ],
      "metadata": {
        "id": "YrxiDVF4Fj3i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このリストを扱う練習として，クラス数，あるクラスに属するデータ，そしてそのサンプル数を取り出す方法を以下に記載します。"
      ],
      "metadata": {
        "id": "BtKAXIKRFvIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# クラス数はリストの要素数である。つまり len(initial_class_list) で得られる。\n",
        "print('Number of classes: ' + str(len(initial_class_list)))\n",
        "\n",
        "# n番目のクラスに属するデータは initial_class_list[n] で得られる。\n",
        "class_data = initial_class_list[0]\n",
        "print('data in class[0]:')\n",
        "# class_data は numpy array型で定義されている。\n",
        "print(type(class_data))\n",
        "print(class_data)\n",
        "\n",
        "# numpy arrayデータの行数は，このクラスに属するデータのサンプル数に相当する。\n",
        "N, D = np.shape(class_data)\n",
        "print('Number of samples in class[0]: ' + str(N))"
      ],
      "metadata": {
        "id": "lJCsqW-SFwAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "階層クラスタリングでは，近いクラス同士を一つにまとめる（マージする）ことで，クラス数を減らしていきます。  \n",
        "例として，0番目のクラスと1番目のクラスをまとめてみます。  \n",
        "これは以下の手順で行います。  \n",
        "* 0番目のクラスのデータと1番目のクラスのデータを <font color=red>**`numpy.vstack`**</font>関数を使って縦に繋げる。\n",
        "* <font color=red>**`append`**</font>関数を使って，繋げたデータをクラスリストの末尾に追加する。\n",
        "* <font color=red>**`del`**</font>関数を使って，1番目のクラス，0番目のクラスを削除する。(このとき，**クラス番号の大きい方から順に削除すること。**)"
      ],
      "metadata": {
        "id": "LF_esISTGCPM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initial_class_list を class_list にコピー\n",
        "class_list = initial_class_list.copy()\n",
        "  \n",
        "# class_list[0] と class_list[1] のデータを縦に繋げることで，統合する。\n",
        "new_class = np.vstack([class_list[0], class_list[1]])\n",
        "\n",
        "# 統合したクラスを class_list の末尾に追加する。\n",
        "class_list.append(new_class)\n",
        "\n",
        "# 統合に使われたクラスを削除する。\n",
        "# 削除は，インデクスの大きいもの(この場合1)から順番に行うこと。先に0を消してしまうとインデクスがずれてしまうため。\n",
        "del(class_list[1])\n",
        "del(class_list[0])\n",
        "\n",
        "# 統合後のクラス数\n",
        "print('Number of classes: ' + str(len(class_list)))\n",
        "\n",
        "# 末尾に追加したデータは class_list[-1]で得られる。(-1はリストの最後尾という意味)\n",
        "class_data = class_list[-1]\n",
        "print('marged class data:')\n",
        "print(type(class_data))\n",
        "print(class_data)\n",
        "\n",
        "# numpy arrayデータの行数は，このクラスに属するデータのサンプル数に相当する。\n",
        "N, D = np.shape(class_data)\n",
        "print('Number of samples in marged class: ' + str(N))"
      ],
      "metadata": {
        "id": "qnM2ZgInIsVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "統合した結果，クラス数が49から48に減り，統合したクラスのサンプル数が2になっているのが確認できます。  "
      ],
      "metadata": {
        "id": "tcNoWxqeKf94"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ステップ4: 最短距離法による階層クラスタリング  \n",
        "クラスリストの準備と統合の実装方法について説明しましたので，  \n",
        "これから最短距離法を使って階層クラスタリングを実行します。"
      ],
      "metadata": {
        "id": "QBg3vcyIKrdC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まずユークリッド距離を計算する関数を以下に定義します。  \n",
        "$d({\\mathbf x}, {\\mathbf y})=\\sqrt{\\sum_{d=1}^{D}(x_{d}-y_{d})^{2}}$  \n",
        "（$x_{d}$はベクトル$\\mathbf x$の$d$次元目の要素。$D$はベクトルの次元数。）"
      ],
      "metadata": {
        "id": "DhSjcfpKFaIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def euclidean_distance(x, y):\n",
        "  '''\n",
        "      ユークリッド距離を計算して出力する\n",
        "      x, y: 距離を測りたい2個の多次元ベクトル\n",
        "  '''\n",
        "  dist = np.sum((x-y)**2)\n",
        "  dist = np.sqrt(dist)\n",
        "  return dist"
      ],
      "metadata": {
        "id": "0aPq6Wmpv5RI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "続いて，クラス1とクラス2の最短距離を計算する関数を以下に定義します。  \n",
        "${\\rm shortest\\_dist}({\\mathbf c}_1, {\\mathbf c}_2) = \\min_{{\\mathbf x}_1 \\in {\\mathbf c}_1, {\\mathbf x}_2 \\in {\\mathbf c}_2} d({\\mathbf x}_1, {\\mathbf x}_2)$"
      ],
      "metadata": {
        "id": "vpjLTYiG4Wdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_shortest_distance(class1, class2):\n",
        "  '''\n",
        "      クラス1(class1)とクラス2(class2)の最短距離を計算\n",
        "      class1: NxDの配列(N:クラス1に属するデータのサンプル数, D:次元)\n",
        "      class2: MxDの配列(M:クラス2に属するデータのサンプル数)\n",
        "  '''\n",
        "  # クラス1のサンプル数Nと次元数Dを得る\n",
        "  N, D = np.shape(class1)\n",
        "  # クラス2のサンプル数Mと次元数Dを得る\n",
        "  M, D = np.shape(class2)\n",
        "\n",
        "  # 距離マトリクスを作成\n",
        "  # dist_matrix[n,m]にはクラス1に属するn番目のサンプルと\n",
        "  # クラス2に属するm番目のサンプルとの距離が格納される\n",
        "  dist_matrix = np.zeros([N, M])\n",
        "  for n in range(N):\n",
        "    for m in range(M):\n",
        "      dist_matrix[n, m] = euclidean_distance(class1[n], class2[m])\n",
        "  \n",
        "  # 最短距離を求める\n",
        "  min_dist = np.min(dist_matrix)\n",
        "\n",
        "  return min_dist"
      ],
      "metadata": {
        "id": "eM6Z035q4ezh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "定義した関数を使って，階層クラスタリングを行います。  \n",
        "ここでは，クラス数が $K=3$ になるまで統合を繰り返すことにします。"
      ],
      "metadata": {
        "id": "0IWqb7IpLHNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "K = 3\n",
        "\n",
        "# クラスの初期状態をコピー\n",
        "class_list = initial_class_list.copy()\n",
        "\n",
        "while True:\n",
        "  # 現在のクラス数を取得\n",
        "  num_classes = len(class_list)\n",
        "\n",
        "  # クラス数が K になっていれば終了\n",
        "  if num_classes == K:\n",
        "    break\n",
        "  \n",
        "  # 最も近いクラスのペアを見つける。\n",
        "  min_dist = 9999999\n",
        "  min_i = 0\n",
        "  min_j = 0\n",
        "  for i in range(num_classes - 1):\n",
        "    for j in range(i+1, num_classes):\n",
        "      # クラスi とクラスj の距離を計算\n",
        "      class_i = class_list[i]\n",
        "      class_j = class_list[j]\n",
        "      dist = get_shortest_distance(class_i, class_j)\n",
        "\n",
        "      if dist < min_dist:\n",
        "        # 距離の最小値を更新\n",
        "        min_dist = dist\n",
        "        min_i = i\n",
        "        min_j = j\n",
        "  \n",
        "  # 今，最も近いクラスのペアは min_i番目と min_j番目のクラスである。\n",
        "  # これらを統合する。\n",
        "\n",
        "  # classes[min_i]とclasses[min_j]を統合する。\n",
        "  new_class = np.vstack([class_list[min_i], class_list[min_j]])\n",
        "\n",
        "  # 統合したクラスをクラスリストの末尾に追加\n",
        "  class_list.append(new_class)\n",
        "\n",
        "  # 統合に使われたクラスを削除する。\n",
        "  # (min_j > min_i のため，先にmin_iを削除するとインデクスがずれる。よってmin_jを先に削除してからmin_iを削除する)\n",
        "  del(class_list[min_j])\n",
        "  del(class_list[min_i])\n"
      ],
      "metadata": {
        "id": "7k4XmKGwLMdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "結果をプロットしてみます。"
      ],
      "metadata": {
        "id": "Qjihrurrlo7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colors = ['r', 'b', 'g', 'c', 'm', 'y']\n",
        "# 二次元データのプロット\n",
        "plt.figure(figsize=(8,8))\n",
        "\n",
        "\n",
        "for k in range(K):\n",
        "  c = colors[k%6] # プロットの色を，クラス番号によって自動的に変える。\n",
        "\n",
        "  # k番目のクラスデータを得る\n",
        "  class_data = class_list[k]\n",
        "  # プロット\n",
        "  plt.scatter(class_data[:,0], class_data[:,1], color=c, label='class: '+str(k+1))\n",
        "plt.xlabel('燃費（標準化済み）')\n",
        "plt.ylabel('排気量（標準化済み）')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tbxODOcLMHGy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "結果から，排気量が多く燃費が悪い車がクラス1（赤），排気量が少なく燃費が良い車がクラス2（青），それ以外がクラス3（緑）というクラスに分けられていることが分かります。"
      ],
      "metadata": {
        "id": "9rCOPZZpRBHF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ステップ5: クラスの統合される様子を可視化  \n",
        "階層クラスタリングによってクラスが統合されていく様子をアニメーションにしてみます。"
      ],
      "metadata": {
        "id": "7ZdfF-tRRAeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import animation, rc\n",
        "from IPython.display import HTML\n",
        "\n",
        "\n",
        "# クラスの初期状態をコピー\n",
        "class_list = initial_class_list.copy()\n",
        "# color_list はクラス毎のプロット時の色を定義するリスト\n",
        "color_list = []\n",
        "for n in range(num_samples):\n",
        "  color_list.append(0)\n",
        "\n",
        "# アニメーション用\n",
        "images = []\n",
        "fig = plt.figure(figsize=(8,8))\n",
        "cmap = plt.cm.get_cmap('tab20').colors #20色のカラーマップ\n",
        "\n",
        "while True:\n",
        "  # 現在のクラス数を取得\n",
        "  num_classes = len(class_list)\n",
        "  # プロット\n",
        "  image_tmp = []\n",
        "  for k in range(num_classes):\n",
        "    # k番目のクラスデータを得る\n",
        "    class_data = class_list[k]\n",
        "    # 色の決定\n",
        "    c_ind = color_list[k] % 20\n",
        "    c_ind = 2*(c_ind % 10) + (c_ind // 10)\n",
        "    if c_ind == 0:\n",
        "      color = 'k'\n",
        "    else:\n",
        "      color = cmap[c_ind]\n",
        "    # プロット\n",
        "    img = plt.scatter(class_data[:,0], class_data[:,1], color=color)\n",
        "    image_tmp.append(img)\n",
        "  img = plt.text(1.0, 2.5, 'Num of classes: '+str(num_classes), size='x-large')\n",
        "  image_tmp.append(img)\n",
        "  images.append(image_tmp)\n",
        "\n",
        "  # クラス数が 1 になっていれば終了\n",
        "  if num_classes == 1:\n",
        "    break\n",
        "  \n",
        "  # 最も近いクラスのペアを見つける。\n",
        "  min_dist = 9999999\n",
        "  min_i = 0\n",
        "  min_j = 0\n",
        "  for i in range(num_classes - 1):\n",
        "    for j in range(i+1, num_classes):\n",
        "      # クラスi とクラスj の距離を計算\n",
        "      dist = get_shortest_distance(class_list[i], class_list[j])\n",
        "\n",
        "      if dist < min_dist:\n",
        "        # 距離の最小値を更新\n",
        "        min_dist = dist\n",
        "        min_i = i\n",
        "        min_j = j\n",
        "  \n",
        "  # classes[min_i]とclasses[min_j]を統合する。\n",
        "  new_class = np.vstack([class_list[min_i], class_list[min_j]])\n",
        "  # 統合したクラスをクラスリストの末尾に追加\n",
        "  class_list.append(new_class)\n",
        "  \n",
        "  # 統合したクラスの色を決める\n",
        "  if color_list[min_i] == 0 and color_list[min_j] == 0:\n",
        "    new_color = max(color_list) + 1\n",
        "  elif color_list[min_i] != 0 and color_list[min_j] != 0:\n",
        "    new_color = min([color_list[min_i], color_list[min_j]])\n",
        "  else:\n",
        "    new_color = max([color_list[min_i], color_list[min_j]])\n",
        "  color_list.append(new_color)\n",
        "\n",
        "  # 統合に使われたクラスを削除する。\n",
        "  del(class_list[min_j])\n",
        "  del(class_list[min_i])\n",
        "  del(color_list[min_j])\n",
        "  del(color_list[min_i])\n",
        "\n",
        "plt.xlabel('燃費（標準化済み）')\n",
        "plt.ylabel('排気量（標準化済み）')\n",
        "\n",
        "# アニメーション作成\n",
        "anim = animation.ArtistAnimation(fig, images, interval=1000)\n",
        "\n",
        "# Google Colaboratoryの場合必要\n",
        "rc('animation', html='jshtml')\n",
        "plt.close()\n",
        "display(anim)"
      ],
      "metadata": {
        "id": "-eeWS5-1R1x6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "上記の結果を見ると，クラス数$K=4$のときでも，少数サンプルのクラスが存在しており，$K=3$でようやくまとまったクラスになっていることが分かります。  \n",
        "$K=2$になると，排気量が多く燃費が悪いクラスと，それ以外のクラスに分かれていることが分かります。  \n",
        "\n",
        "K-meansのような非階層クラスタリングでは分割クラス数$K$を変えるたびに処理を最初からやり直す必要があるのに対して，階層クラスタリングは一度実行しておけば，全ての分割数に対するクラスタリング結果が得られる点が長所の一つです。  \n",
        "またそれにより，結果を確認しながら最適な分割数を見つけることができます。  \n",
        "\n",
        "一方，非階層クラスタリングと比べて計算量が多い点は短所です。"
      ],
      "metadata": {
        "id": "LFqO9D1cgvml"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## おまけ  \n",
        "最短距離法の関数 `get_shortest_distance` で最小距離を計算している部分（np.min(dist_matrix)）を最大距離の計算（np.max(dist_matrix)）に置き換えるだけで，最長距離法の計算になります。  \n",
        "興味のある方はこの関数を使って階層クラスタリングを行い，最短距離法の結果を見比べてみてください。"
      ],
      "metadata": {
        "id": "N6heCBmakfI5"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U5lG9p-iYeB"
      },
      "source": [
        "def get_longest_distance(class1, class2):\n",
        "  '''\n",
        "      クラス1(class1)とクラス2(class2)の最長距離を計算\n",
        "      class1: NxDの配列(N:クラス1に属するデータのサンプル数, D:次元)\n",
        "      class2: MxDの配列(M:クラス2に属するデータのサンプル数)\n",
        "  '''\n",
        "  # クラス1のサンプル数Nと次元数Dを得る\n",
        "  N, D = np.shape(class1)\n",
        "  # クラス2のサンプル数Mと次元数Dを得る\n",
        "  M, D = np.shape(class2)\n",
        "\n",
        "  # 距離マトリクスを作成\n",
        "  # dist_matrix[n,m]にはクラス1に属するn番目のサンプルと\n",
        "  # クラス2に属するm番目のサンプルとの距離が格納される\n",
        "  dist_matrix = np.zeros([N, M])\n",
        "  for n in range(N):\n",
        "    for m in range(M):\n",
        "      dist_matrix[n, m] = euclidean_distance(class1[n], class2[m])\n",
        "  \n",
        "  # 最長距離を求める\n",
        "  max_dist = np.max(dist_matrix)\n",
        "\n",
        "  return max_dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrvQ9flV7zEO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}