{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "08_03_gmm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbqkmaY9RA-z"
      },
      "source": [
        "# 第8回 その3: 混合正規分布\n",
        "5教科テストデータに対して 混合正規分布を用いたクラス分類を行ってみましょう。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srIl-shURTM2"
      },
      "source": [
        "## ステップ0: Google Driveのマウントと作業フォルダへの移動  \n",
        "Google Drive に配置したデータを読み込むための準備です。  \n",
        "詳細については第二回の 02_01_graph.ipynb を参照してください。  \n",
        "\n",
        "ここでは\"マイドライブ/情報管理/08\"を作業フォルダとします。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf9ghfr_QzT1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# フォルダの移動には\"%cd\"を使用します。\n",
        "# 作業フォルダへ移動\n",
        "%cd /content/drive/'My Drive'/情報管理/08/\n",
        "# 現在のフォルダの中身を表示\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNGpM3FYRiob"
      },
      "source": [
        "`gokyouka.csv`というデータが表示されていることを確認してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1DmeW6oRs8r"
      },
      "source": [
        "## ステップ1: データの読み込み\n",
        "まずは必要ライブラリをインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4b4cfHPRXML"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF6-hyJ2Sdau"
      },
      "source": [
        "`gokyouka.csv` を読み込みます。  \n",
        "このデータは第2回のレポート課題で使用した，5教科のテストの点数を示したデータ(report02_input.csv)です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkibCXvsRv-8"
      },
      "source": [
        "# pandas の関数 read_csv を用いた csvファイル読み込み\n",
        "csv_data = pd.read_csv('gokyouka.csv', encoding='SHIFT-JIS')\n",
        "# データの前半部(.headで取得できる)のみ表示\n",
        "display(csv_data.head())\n",
        "\n",
        "# numpy用データ(ndarray型) に変換する。\n",
        "X = csv_data.to_numpy()\n",
        "\n",
        "# データのサンプル数と次元数を得る。\n",
        "(num_samples, num_dimensions) = np.shape(X)\n",
        "print('Nunber of samples: ' + str(num_samples))\n",
        "print('Number of dimensions: ' + str(num_dimensions))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glCVWFIRID3y"
      },
      "source": [
        "## ステップ2: 主成分分析によるデータの2次元への圧縮  \n",
        "08_02_kmeans.ipynbと同様に，主成分分析を使って2次元に圧縮します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Em_IcIDIL6A"
      },
      "source": [
        "# データの標準化\n",
        "X_norm = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "# 分散共分散行列の計算\n",
        "cov = np.cov(X_norm.T, bias=True)\n",
        "# 固有値分解\n",
        "eig_val, eig_vec =np.linalg.eig(cov)\n",
        "\n",
        "# 固有値を大きい順に並び替える\n",
        "order = np.argsort(eig_val)[::-1]\n",
        "eig_val = eig_val[order]\n",
        "eig_vec_pca = eig_vec[:,order]\n",
        "\n",
        "# 第二主成分までの固有ベクトルを用いて次元圧縮\n",
        "X_pca = np.dot(X_norm, eig_vec_pca[:,:2])\n",
        "\n",
        "# 二次元データのプロット\n",
        "plt.figure(figsize=(10,6))\n",
        "plt.scatter(X_pca[:,0], X_pca[:,1], color='k')\n",
        "plt.xlabel('1st principal component')\n",
        "plt.ylabel('2nd principal component')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68gTNlhd51uR"
      },
      "source": [
        "主成分分析によって2次元圧縮したデータが `X_pca` に格納されました。  \n",
        "以降は `X_pca` に対して k-means を行います。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12eW3PQc_5Lh"
      },
      "source": [
        "## ステップ3: K-means による3クラスのクラスタリング  \n",
        "比較のため，まずはK-meansによるクラスタリングを行います。  \n",
        "以下は k-means の関数の実装(06_02_kmeans.ipynb参照)です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U5lG9p-iYeB"
      },
      "source": [
        "def euclidean_distance(x, y):\n",
        "  '''\n",
        "      ユークリッド距離を計算して出力する\n",
        "      x, y: 距離を測りたい2個の多次元ベクトル\n",
        "  '''\n",
        "  dist = np.sum((x-y)**2)\n",
        "  return dist\n",
        "\n",
        "def k_means(centroid, data):\n",
        "  '''\n",
        "     k-means によるセントロイドの更新を1回行う。\n",
        "     入力\n",
        "     centroid: 現在のセントロイド\n",
        "     data: データ\n",
        "     出力\n",
        "     new_centroid: 更新後のセントロイド\n",
        "     assigned_class: 各データが振り分けられたクラス番号\n",
        "  '''\n",
        "  # クラス数を取得\n",
        "  num_classes, num_dimensions = np.shape(centroid)\n",
        "  # データのサンプル数と次元数を取得\n",
        "  num_samples, num_dimensions = np.shape(data)\n",
        "\n",
        "  # 各データに対して割り当てるクラス番号\n",
        "  assigned_class = np.zeros(num_samples)\n",
        "\n",
        "  # 各データに対して，最もセントロイドが近いクラスを割り当てる\n",
        "  for n in range(num_samples):\n",
        "    # 各クラスのセントロイドとの距離を測る\n",
        "    dists = np.zeros(num_classes)\n",
        "    for k in range(num_classes):\n",
        "      # n番目のデータとk番目のセントロイドの距離\n",
        "      dists[k] = euclidean_distance(data[n,:], centroid[k,:])\n",
        "\n",
        "    # セントロイドとの距離が最小のクラス番号を割り当てる\n",
        "    assigned_class[n] = np.argmin(dists)\n",
        "  \n",
        "  # セントロイドの更新\n",
        "  new_centroid = np.zeros((num_classes, num_dimensions))\n",
        "  for k in range(num_classes):\n",
        "    # k番目のクラスに該当するデータ data[assigned_class==k] の平均値を\n",
        "    # k番目のクラスの新たなセントロイドとする\n",
        "    new_centroid[k] = np.mean(data[assigned_class==k,:], axis=0)\n",
        "  \n",
        "  return new_centroid, assigned_class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HDqiOsmPjDl"
      },
      "source": [
        "分割するクラスの数 $K=3$ としてセントロイド初期値を設定し，k-meansを実行します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EU8fP3-zI3Gu"
      },
      "source": [
        "#クラス数\n",
        "K = 3\n",
        "\n",
        "#\n",
        "# セントロイド初期値の設定(06_01_kmeans.ipynb参照)\n",
        "#\n",
        "# 乱数シードの設定(ここではシードを5としていますが，何でも良いです)\n",
        "np.random.seed(5)\n",
        "# 0～99 をランダムに並び替える\n",
        "shuffle_index = np.random.permutation(np.arange(num_samples))\n",
        "# 並び替えた数の先頭 K個を取り出して、セントロイドの初期値とする。\n",
        "centroid_index = shuffle_index[:K]\n",
        "initial_centroid = X_pca[centroid_index,:]\n",
        "\n",
        "\n",
        "#\n",
        "# K-means を実行する(06_01_kmeans.ipynb参照)\n",
        "#\n",
        "\n",
        "# 最大更新回数を100とする\n",
        "max_iter = 100\n",
        "\n",
        "centroid = initial_centroid\n",
        "\n",
        "# ループの回数は max_iter とする\n",
        "for n in range(max_iter):\n",
        "  print('Iteration: ' + str(n+1))\n",
        "\n",
        "  # k-meansによるセントロイドの更新を実施\n",
        "  new_centroid, assigned_class = k_means(centroid, X_pca)\n",
        "\n",
        "  # セントロイドが変わっていない，\n",
        "  # つまり更新前後のセントロイドの移動距離が0の場合，ループを抜ける\n",
        "  if np.sum((new_centroid - centroid)**2) == 0:\n",
        "    print('centroids converged')\n",
        "    break\n",
        "  \n",
        "  # セントロイドの更新\n",
        "  centroid = new_centroid"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_rWAkzNfy-8"
      },
      "source": [
        "結果をプロットしてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOoTD3-lf21E"
      },
      "source": [
        "colors = ['r', 'b', 'g', 'c', 'm', 'y']\n",
        "# 二次元データのプロット\n",
        "plt.figure(figsize=(10,6))\n",
        "# セントロイドを\"x\"印でプロット \n",
        "for k in range(K):\n",
        "  c = colors[k%6] # プロットの色を，クラス番号によって自動的に変える。\n",
        "  # 全データのプロット\n",
        "  plt.scatter(X_pca[assigned_class==k,0], X_pca[assigned_class==k,1], color=c, label='class: '+str(k+1))\n",
        "  # セントロイドを \"x\"印でプロット\n",
        "  plt.scatter(centroid[k,0], centroid[k,1], label='centroid: '+str(k+1), color=c, marker='x', s=100)\n",
        "plt.xlabel('1st principal component')\n",
        "plt.ylabel('2nd principal component')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXEj6SrYf7H1"
      },
      "source": [
        "上記の結果では，成績が普通のクラス(文系)と成績が悪いクラスが緑色のクラス3でまとまってクラス化されていることから，この結果は直感と異なるクラスタリングがされていると言えます。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNJnhxAs9jaK"
      },
      "source": [
        "## ステップ4: 混合正規分布によるクラスタリング  \n",
        "では混合正規分布を使って，3クラスのクラスタリングを実行してみましょう。  \n",
        "\n",
        "ここでは機械学習系のライブラリであるscikit-learn (sklearn)からmixtureというモジュールをインポートすることで，混合正規分布を実行しています。  \n",
        "（ソースコードの実装はレポート課題です。）"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U73zwU_mgU3y"
      },
      "source": [
        "from sklearn import mixture\n",
        "\n",
        "gmm = mixture.GaussianMixture(n_components=K)\n",
        "gmm_res = gmm.fit(X_pca)\n",
        "# クラスタリング結果\n",
        "assigned_class_gmm = gmm_res.predict(X_pca)\n",
        "# 平均値ベクトル\n",
        "means = gmm_res.means_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PrldnRkh4i6"
      },
      "source": [
        "結果をプロットしてみましょう。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uU0Xm86hZKV"
      },
      "source": [
        "colors = ['r', 'b', 'g', 'c', 'm', 'y']\n",
        "# 二次元データのプロット\n",
        "plt.figure(figsize=(10,6))\n",
        "# セントロイドを\"x\"印でプロット \n",
        "for k in range(K):\n",
        "  c = colors[k%6] # プロットの色を，クラス番号によって自動的に変える。\n",
        "  # 全データのプロット\n",
        "  plt.scatter(X_pca[assigned_class_gmm==k,0], X_pca[assigned_class_gmm==k,1], color=c, label='class: '+str(k+1))\n",
        "  # セントロイドを \"x\"印でプロット\n",
        "  plt.scatter(means[k,0], means[k,1], label='means: '+str(k+1), color=c, marker='x', s=100)\n",
        "plt.xlabel('1st principal component')\n",
        "plt.ylabel('2nd principal component')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFb0rbMuiC43"
      },
      "source": [
        "混合正規分布によるクラスタリング結果は，成績が良いクラス，成績が普通のクラス，成績が悪いクラスに分かれていることから，直感に近いクラスタリング結果になっていると言えます。"
      ]
    }
  ]
}