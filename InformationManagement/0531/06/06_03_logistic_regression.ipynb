{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_03_logistic_regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbqkmaY9RA-z"
      },
      "source": [
        "# 第6回 その2: ロジスティック回帰を用いた教師ありクラスタリング\n",
        "06_01_linear_discriminant_analysis.ipynbと同じデータに対して，ロジスティック回帰を用いた教師ありクラスタリングを行います。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1DmeW6oRs8r"
      },
      "source": [
        "## ステップ0: Google Driveのマウントと作業フォルダへの移動  \n",
        "Google Drive に配置したデータを読み込むための準備です。  \n",
        "詳細については第二回の 02_01_graph.ipynb を参照してください。  \n",
        "\n",
        "ここでは\"マイドライブ/情報管理/06\"を作業フォルダとします。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4b4cfHPRXML"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# フォルダの移動には\"%cd\"を使用します。\n",
        "# 作業フォルダへ移動\n",
        "%cd /content/drive/'My Drive'/情報管理/06/\n",
        "# 現在のフォルダの中身を表示\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF6-hyJ2Sdau"
      },
      "source": [
        "`2class_data.csv`というデータが表示されていることを確認してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ステップ1: データの読み込みと標準化\n",
        "まずは必要ライブラリをインポートします。"
      ],
      "metadata": {
        "id": "_zJI0HyoWGGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "SYfdOuD_WNd_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`2class_data.csv` を読み込みます。  \n",
        "このデータx1とx2の二次元データで，クラス0とクラス1の2種類のクラスのどちらかに属しています。"
      ],
      "metadata": {
        "id": "SXb_O89VWQQY"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkibCXvsRv-8"
      },
      "source": [
        "# pandas の関数 read_csv を用いた csvファイル読み込み\n",
        "csv_data = pd.read_csv('2class_data.csv', encoding='SHIFT-JIS')\n",
        "\n",
        "# データの前半部(.headで取得できる)のみ表示\n",
        "display(csv_data.head())\n",
        "\n",
        "# x1とx2のデータを抽出し，numpy用データ(ndarray型) に変換する。\n",
        "X = csv_data.loc[:, ['x1','x2']].to_numpy()\n",
        "\n",
        "# クラス番号を抽出し，numpy用データ(ndarray型) に変換する。\n",
        "Y = csv_data.loc[:,'class'].to_numpy()\n",
        "\n",
        "# データのサンプル数と次元数を得る。\n",
        "(num_samples, num_dimensions) = np.shape(X)\n",
        "print('Nunber of samples: ' + str(num_samples))\n",
        "print('Number of dimensions: ' + str(num_dimensions))\n",
        "\n",
        "# クラス数を得る。\n",
        "num_classes = int(np.max(Y) + 1)\n",
        "print('Number of classes: ' + str(num_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "標準化を行い，データをプロットします。"
      ],
      "metadata": {
        "id": "A2xHCAEBWdLt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データを標準化する。\n",
        "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "# データをプロット\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.scatter(X[Y==0,0], X[Y==0,1], c='b', label='class0')\n",
        "plt.scatter(X[Y==1,0], X[Y==1,1], c='r', label='class1')\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.legend()\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.xlim([-3, 3])\n",
        "plt.ylim([-3, 3])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2l_DJKdxWf0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ステップ2: ロジスティック回帰\n",
        "ロジスティック回帰を行います。  \n",
        "二次元のデータを${\\bf x} = [x_1, x_2]$としたとき，ロジスティック回帰は以下の式になります。  \n",
        "$\\hat{y} = \\frac{1}{1+e^{-z}}$  \n",
        "$z = w_0 + w_1x_1 + w_2x_2$  \n",
        "$z$の式については，${\\bf w} = [w_0, w_1, w_2]$，${\\bf x}_{\\rm mod} = [1, x_1, x_2]^{T}$と置くことで，  \n",
        "$z = {\\bf w}{\\bf x}_{\\rm mod}$  \n",
        "とも書けます。  以下のソースコードではこの書き方を使うことで，実装をシンプルにしています。   "
      ],
      "metadata": {
        "id": "kxl2IKgJWiM-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず，$\\bf w$ の初期値を決めます。  \n",
        "w_0，つまり切片の初期値はゼロとし，w_1以降，つまりデータの各次元に関する重みの成分は正規分布に従う乱数で決めます。"
      ],
      "metadata": {
        "id": "0idvxBemqOeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "initial_w = np.append(0, np.random.randn(num_dimensions))\n",
        "\n",
        "print('w = ' + str(initial_w))"
      ],
      "metadata": {
        "id": "iON3maL-o9AV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "初期値における境界線をプロットします。  \n",
        "境界線は$z = w_0 + w_1x_1 + w_2x_2 = 0$ですので，  \n",
        "$x_2 = -(w_0 + w_1x_1) / w_2$  \n",
        "と変形したものをプロットします。  \n",
        "(正確には境界線は$\\hat{y} = \\frac{1}{1+e^{-z}} = 0.5$ですが，$\\hat{y}$が0.5となるのは$z$が0のときなので，実質的な境界線は$z = 0$となります。)"
      ],
      "metadata": {
        "id": "Q10ro6XQRZEl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データをプロット\n",
        "x1 = np.linspace(-3, 3)\n",
        "x2 = -1.0 * (initial_w[0] + initial_w[1]*x1) / initial_w[2]\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.plot(x1, x2)\n",
        "plt.scatter(X[Y==0,0], X[Y==0,1], c='b', label='class1')\n",
        "plt.scatter(X[Y==1,0], X[Y==1,1], c='r', label='class2')\n",
        "plt.legend()\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.xlim([-3, 3])\n",
        "plt.ylim([-3, 3])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4KKtTB4mX4Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "初期値ですので，正確に分離できていない境界線となっています。  \n",
        "例として，この状態で一度ロジスティック回帰を実行してみましょう。"
      ],
      "metadata": {
        "id": "OViMDQCAZcUe"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RmuM3aYnanP"
      },
      "source": [
        "1サンプルデータに対してロジスティック回帰を行う関数を以下に定義します。  \n",
        "\n",
        "シグモイド関数の定義  \n",
        "${\\rm sigmoid}(z) = \\frac{1}{1+e^{-z}}$  \n",
        "ロジスティック回帰の定義  \n",
        "$\\hat{y} = sigmoid(z)$  \n",
        "$z = w_0 + w_1x_1 + w_2x_2 + \\dots = [w_0, w_1, w_2, \\dots][1, x_1, x_2, \\dots]^{T}$  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkdO-S8SuDPX"
      },
      "source": [
        "def sigmoid(z):\n",
        "  '''\n",
        "      シグモイド関数\n",
        "  '''\n",
        "  return (1+np.exp(-1*z))**(-1)\n",
        "\n",
        "def logistic_regression(x, w):\n",
        "  '''\n",
        "      1サンプルデータに対してロジスティック回帰を行う\n",
        "      x: 1サンプルデータ。要素数=次元数のベクトル\n",
        "      w: 切片と各次元に対する重み。要素数=(次元数+1)のベクトル(+1は切片の分)\n",
        "         wの0次元目は切片。1次元目以降からxの各次元に対する重みが入る。\n",
        "      y_hat: ロジスティック回帰の出力。スカラー値\n",
        "  '''\n",
        "  # xの先頭に1(切片に相当)を加えたベクトルを作成\n",
        "  # numpy append 関数：ベクトル同士をくっつけて一つのベクトルにする。\n",
        "  x_mod = np.append(1, x)\n",
        "\n",
        "  # z = w0 + w1*x1 + w2*x2 + ...\n",
        "  z = np.dot(w, x_mod)\n",
        "\n",
        "  # シグモイド関数に通す\n",
        "  y_hat = sigmoid(z)\n",
        "\n",
        "  return y_hat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "例として5番目のサンプルデータに対してロジスティック回帰を行い，クラス識別を行います。  \n",
        "ロジスティック回帰の出力$\\hat{y}$は0～1の範囲の連続値ですので，$\\hat{y} > 0.5$の場合はクラス1，$\\hat{y} \\leq 0.5$の場合はクラス0と識別します。"
      ],
      "metadata": {
        "id": "KS1T7iJCaW8_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 5番目のデータで試す\n",
        "sample_id = 5\n",
        "w = initial_w.copy()\n",
        "x = X[sample_id,:]\n",
        "y = Y[sample_id]\n",
        "\n",
        "# ロジスティック回帰関数に与える\n",
        "y_hat = logistic_regression(x, w)\n",
        "\n",
        "# y_hatが0.5を超える場合はクラス1，以下の場合はクラス0と判定する\n",
        "if y_hat > 0.5:\n",
        "  pred = 1\n",
        "else:\n",
        "  pred = 0\n",
        "\n",
        "print('y_hat = ' + str(y_hat))\n",
        "print('estimated label = ' + str(pred))\n",
        "print('true label = ' + str(y))\n",
        "\n",
        "# データをプロット\n",
        "x1 = np.linspace(-3, 3)\n",
        "x2 = -1.0 * (w[0] + w[1]*x1) / w[2]\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.plot(x1, x2)\n",
        "plt.scatter(X[Y==0,0], X[Y==0,1], c='b', label='class1')\n",
        "plt.scatter(X[Y==1,0], X[Y==1,1], c='r', label='class2')\n",
        "plt.scatter(x[0], x[1], c='g')\n",
        "plt.scatter(x[0], x[1], c='g', marker='x', s=100, label='tested sample')\n",
        "plt.legend()\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.xlim([-3, 3])\n",
        "plt.ylim([-3, 3])\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TB_Mx3knvEd2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "estimated label（識別結果）は1で，true label(正解ラベル)は0なので，この識別結果は誤りです。  "
      ],
      "metadata": {
        "id": "Q7x1npYYa_Hk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "次に，このときの勾配を計算してみます。"
      ],
      "metadata": {
        "id": "MNuvAlY5bSBx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "まず，勾配を計算する関数を以下に定義します。    \n",
        "$\\frac{\\partial L_{mse}}{\\partial \\bf w} = (\\hat{y} - y)(1 - \\hat{y})\\hat{y}[1, x_1, x_2, \\dots]$"
      ],
      "metadata": {
        "id": "gu0ihSZ-tPcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_gradient(y_hat, y, x):\n",
        "  '''\n",
        "      勾配を計算する\n",
        "      y_hat: ロジスティック回帰によって推定された y\n",
        "      y: 正解のy\n",
        "      x: データ\n",
        "  '''\n",
        "  # xの先頭に1(切片に相当)を加えたベクトルを作成\n",
        "  # numpy append 関数：ベクトル同士をくっつけて一つのベクトルにする。\n",
        "  x_mod = np.append(1, x)\n",
        "\n",
        "  gradient = (y_hat - y)*(1 - y_hat)*y_hat * x_mod\n",
        "\n",
        "  return gradient"
      ],
      "metadata": {
        "id": "1G33yRYprRsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "定義した関数を使って，勾配を計算します。"
      ],
      "metadata": {
        "id": "hoH7Ox-M0aYu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "grad = calc_gradient(y_hat, y, x)\n",
        "print('gradient of L for w = ' + str(grad))"
      ],
      "metadata": {
        "id": "yTZrTs3KvlYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "計算された勾配を使って，\n",
        "${\\bf w}_{\\rm next} = {\\bf w} - \\mu \\frac{\\partial L_{mse}}{\\partial \\bf w}$により，${\\bf w}$を更新してみます。  \n",
        "ここでは，$\\mu = 0.2$とします。"
      ],
      "metadata": {
        "id": "Hjt2siNKcJhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習率(lr = learning rate)\n",
        "lr = 0.2\n",
        "\n",
        "# 勾配を使って w を更新\n",
        "w_next = w - lr * grad\n",
        "\n",
        "# プロット\n",
        "x1 = np.linspace(-3, 3)\n",
        "x2next = -1.0 * (w_next[0] + w_next[1]*x1) / w_next[2]\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.plot(x1, x2, label='initial boundary')\n",
        "plt.plot(x1, x2next, label='updated boundary')\n",
        "plt.scatter(X[Y==0,0], X[Y==0,1], c='b', label='class1')\n",
        "plt.scatter(X[Y==1,0], X[Y==1,1], c='r', label='class2')\n",
        "plt.scatter(x[0], x[1], c='g')\n",
        "plt.scatter(x[0], x[1], c='g', marker='x', s=100, label='tested sample')\n",
        "plt.legend()\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.xlim([-3, 3])\n",
        "plt.ylim([-3, 3])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "IVSfCsDp0hlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ほんの少しですが，境界線の傾きが負の方向に更新されました。  \n",
        "\n",
        "更新前と更新後のロジスティック回帰の出力$\\hat{y}$を見比べてみましょう。  \n"
      ],
      "metadata": {
        "id": "o_hJk_731p2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_hat_old = logistic_regression(x, w)\n",
        "y_hat_next = logistic_regression(x, w_next)\n",
        "print('y_hat_old = ' + str(y_hat_old))\n",
        "print('y_hat_next = ' + str(y_hat_next))"
      ],
      "metadata": {
        "id": "2vQXg694dVfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "更新により，ロジスティック回帰の出力がほんの少し小さくなった，つまり正解ラベル0にほんの少し近くなった，ということが分かります。"
      ],
      "metadata": {
        "id": "VVv8mWCFdtPk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "では，全てのデータに対してロジスティック回帰および勾配の計算を行い，サンプル毎に$\\bf w$の更新を行いましょう。  "
      ],
      "metadata": {
        "id": "TKI-bcdJXlhT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import animation, rc\n",
        "from IPython.display import HTML\n",
        "\n",
        "# 学習率\n",
        "lr = 0.2\n",
        "\n",
        "# 重みの初期化\n",
        "w = initial_w.copy()\n",
        "\n",
        "# 描画\n",
        "fig = plt.figure(figsize=(7,7))\n",
        "# データの描画\n",
        "plt.scatter(X[Y==0,0], X[Y==0,1], c='b', label='class1')\n",
        "plt.scatter(X[Y==1,0], X[Y==1,1], c='r', label='class2')\n",
        "images = []\n",
        "\n",
        "# 全サンプルを読み込んで，サンプル毎に更新を行う。\n",
        "for n in range(num_samples):\n",
        "  x = X[n,:]\n",
        "  y = Y[n]\n",
        "  \n",
        "  # ロジスティック回帰関数に与える\n",
        "  y_hat = logistic_regression(x, w)\n",
        "  \n",
        "  # 勾配の計算\n",
        "  grad = calc_gradient(y_hat, y, x)\n",
        "\n",
        "  # 毎回アニメーションを更新すると時間がかかるので，4サンプル毎にアニメーションを更新する。\n",
        "  if n % 4 == 0:\n",
        "    x2 = -1.0 * (w[0] + w[1]*x1) / w[2]\n",
        "    img = plt.plot(x1, x2, c='b')\n",
        "    images.append(img)\n",
        "\n",
        "  # 更新\n",
        "  w -= lr * grad\n",
        "\n",
        "plt.legend()\n",
        "plt.xlim([-3, 3])\n",
        "plt.ylim([-3, 3])\n",
        "\n",
        "# アニメーション作成\n",
        "anim = animation.ArtistAnimation(fig, images, interval=100)\n",
        "# Google Colaboratoryの場合必要\n",
        "rc('animation', html='jshtml')\n",
        "plt.close()\n",
        "display(anim)"
      ],
      "metadata": {
        "id": "sPxGE5KdX0Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "理想的な分離境界に近づいてきましたが，まだ完全に分離できていないまま，全データが処理されてしまいました。  \n",
        "\n",
        "そこで，データをシャッフルし直して，再度全データを読み込み，$\\bf w$の更新を行います。  \n",
        "ここで，全データを読み込んで更新するまでの処理1週分を<font color='red'>**エポック**</font>と呼びます。  \n",
        "以下の処理では，全データを50周，つまり50エポック分，$\\bf w$の更新を行います。"
      ],
      "metadata": {
        "id": "eIkxrQ3sY_Tb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import animation, rc\n",
        "from IPython.display import HTML\n",
        "\n",
        "np.random.seed(0)\n",
        "\n",
        "# 学習率\n",
        "lr = 0.2\n",
        "\n",
        "# 重みの初期化\n",
        "w = initial_w.copy()\n",
        "\n",
        "# 描画\n",
        "fig = plt.figure(figsize=(7,7))\n",
        "# データの描画\n",
        "plt.scatter(X[Y==0,0], X[Y==0,1], c='b', label='class1')\n",
        "plt.scatter(X[Y==1,0], X[Y==1,1], c='r', label='class2')\n",
        "images = []\n",
        "\n",
        "# yの誤差の履歴\n",
        "mse_history = np.array([])\n",
        "\n",
        "for epoch in range(50):\n",
        "  \n",
        "  # データをシャッフルしなおす。\n",
        "  # (局所解に陥りにくくなるため)\n",
        "  shuffle_index = np.random.permutation(np.arange(num_samples))\n",
        "  X_tmp = X[(shuffle_index)]\n",
        "  Y_tmp = Y[(shuffle_index)]\n",
        "  \n",
        "  mse = 0\n",
        "  for n in range(num_samples):\n",
        "    x = X_tmp[n,:]\n",
        "    y = Y_tmp[n]\n",
        "  \n",
        "    # ロジスティック回帰関数に与える\n",
        "    y_hat = logistic_regression(x, w)\n",
        "  \n",
        "    # 勾配の計算\n",
        "    grad = calc_gradient(y_hat, y, x)\n",
        "\n",
        "    # 毎回アニメーションを更新すると時間がかかるので，200サンプル毎にアニメーションを更新する。\n",
        "    if n % 400 == 0:\n",
        "      x2 = -1.0 * (w[0] + w[1]*x1) / w[2]\n",
        "      img = plt.plot(x1, x2, c='b')\n",
        "      img.append(plt.text(-2.8, 2.5, 'epoch: '+str(epoch), size='x-large'))\n",
        "      images.append(img)\n",
        "\n",
        "    # 更新\n",
        "    w -= lr * grad\n",
        "\n",
        "    # yの誤差を蓄積\n",
        "    mse += (y - y_hat)**2\n",
        "  \n",
        "  mse /= num_samples\n",
        "  mse_history = np.append(mse_history, mse)\n",
        "  print('%d-th epoch: mean square error = %.3f' % (epoch+1, mse))\n",
        "\n",
        "plt.legend()\n",
        "plt.xlim([-3, 3])\n",
        "plt.ylim([-3, 3])\n",
        "\n",
        "# アニメーション作成\n",
        "anim = animation.ArtistAnimation(fig, images, interval=100)\n",
        "# Google Colaboratoryの場合必要\n",
        "rc('animation', html='jshtml')\n",
        "plt.close()\n",
        "display(anim)"
      ],
      "metadata": {
        "id": "6YmZ596h0-lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "mean square error は 正解の$y$とロジスティック回帰が出力した$\\hat{y}$の平均二乗誤差  \n",
        "${\\rm MSE} = \\frac{1}{N}\\sum_{n=1}^{N}(y_n - \\hat{y}_{n})^2$  \n",
        "です。エポック毎のMSEをプロットしてみます。"
      ],
      "metadata": {
        "id": "je4-8YEccEJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(7,5))\n",
        "plt.plot(mse_history)\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('mean square error')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nIjzgawo2NbZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "更新が進むにつれて，$y$と$\\hat{y}$の誤差が小さくなっているのが分かります。"
      ],
      "metadata": {
        "id": "MJrfW0A3dInq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "最後に，分類正解率を計算します。  "
      ],
      "metadata": {
        "id": "5OL88EjpdRZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 正解率\n",
        "accuracy = 0\n",
        "\n",
        "for n in range(num_samples):\n",
        "  x = X[n,:]\n",
        "  y = Y[n]\n",
        "  # ロジスティック回帰関数に与える\n",
        "  y_hat = logistic_regression(x, w)\n",
        "\n",
        "  if y_hat > 0.5 and y == 1:\n",
        "    # ロジスティック回帰出力が0.5より大きく，かつ正解ラベルが1\n",
        "    accuracy += 1\n",
        "  elif y_hat <= 0.5 and y == 0:\n",
        "    # ロジスティック回帰出力が0.5以下，かつ正解ラベルが0\n",
        "    accuracy += 1\n",
        "\n",
        "accuracy = 100.0 * accuracy / num_samples\n",
        "\n",
        "print('Accuracy = %.3f' % (accuracy))"
      ],
      "metadata": {
        "id": "8KgbvmdvcwPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ロジスティック回帰でも100%の正解率が得られました。"
      ],
      "metadata": {
        "id": "RztiWfSZeRPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "v5m6zt4SeQCL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}