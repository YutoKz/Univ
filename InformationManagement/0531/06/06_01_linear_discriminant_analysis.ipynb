{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "06_01_linear_discriminant_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbqkmaY9RA-z"
      },
      "source": [
        "# 第6回 その1: 線形判別分析を用いた教師ありクラスタリング\n",
        "第5回で紹介した線形判別分析を使って教師有りクラスタリングを行います。  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ステップ0: Google Driveのマウントと作業フォルダへの移動  \n",
        "Google Drive に配置したデータを読み込むための準備です。  \n",
        "詳細については第二回の 02_01_graph.ipynb を参照してください。  \n",
        "\n",
        "ここでは\"マイドライブ/情報管理/06\"を作業フォルダとします。 "
      ],
      "metadata": {
        "id": "U1Pj2rcbB4Jh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# フォルダの移動には\"%cd\"を使用します。\n",
        "# 作業フォルダへ移動\n",
        "%cd /content/drive/'My Drive'/情報管理/06/\n",
        "# 現在のフォルダの中身を表示\n",
        "%ls"
      ],
      "metadata": {
        "id": "He0jeP7VB-Qo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`2class_data.csv`というデータが表示されていることを確認してください。"
      ],
      "metadata": {
        "id": "cQkYRZgwCG5J"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1DmeW6oRs8r"
      },
      "source": [
        "## ステップ1: データの読み込みと標準化\n",
        "まずは必要ライブラリをインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4b4cfHPRXML"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF6-hyJ2Sdau"
      },
      "source": [
        "`2class_data.csv` を読み込みます。  \n",
        "このデータx1とx2の二次元データで，クラス0とクラス1の2種類のクラスのどちらかに属しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkibCXvsRv-8"
      },
      "source": [
        "# pandas の関数 read_csv を用いた csvファイル読み込み\n",
        "csv_data = pd.read_csv('2class_data.csv', encoding='SHIFT-JIS')\n",
        "\n",
        "# データの前半部(.headで取得できる)のみ表示\n",
        "display(csv_data.head())\n",
        "\n",
        "# x1とx2のデータを抽出し，numpy用データ(ndarray型) に変換する。\n",
        "X = csv_data.loc[:, ['x1','x2']].to_numpy()\n",
        "\n",
        "# クラス番号を抽出し，numpy用データ(ndarray型) に変換する。\n",
        "Y = csv_data.loc[:,'class'].to_numpy()\n",
        "\n",
        "# データのサンプル数と次元数を得る。\n",
        "(num_samples, num_dimensions) = np.shape(X)\n",
        "print('Nunber of samples: ' + str(num_samples))\n",
        "print('Number of dimensions: ' + str(num_dimensions))\n",
        "\n",
        "# クラス数を得る。\n",
        "num_classes = int(np.max(Y) + 1)\n",
        "print('Number of classes: ' + str(num_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0RmuM3aYnanP"
      },
      "source": [
        "標準化を行い，データをプロットします。"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# データを標準化する。\n",
        "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "# データをプロット\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.scatter(X[Y==0,0], X[Y==0,1], c='b', label='class0')\n",
        "plt.scatter(X[Y==1,0], X[Y==1,1], c='r', label='class1')\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.legend()\n",
        "plt.xlim([-3, 3])\n",
        "plt.ylim([-3, 3])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3j_cKrByDfh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ステップ2: 線形判別分析  \n",
        "線形判別分析を行います。  \n",
        "以下のソースコードは第5回の`05_02_lda.ipynb`を流用したものです。  \n",
        "\n",
        "まずはクラス内分散-クラス間分散比の行列を計算します。"
      ],
      "metadata": {
        "id": "6t7sfIoDEDiI"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBozvGsXm0S3"
      },
      "source": [
        "# クラス全体の平均\n",
        "m_all = np.mean(X, axis=0)\n",
        "\n",
        "# クラス内分散共分散\n",
        "cov_inner = np.zeros((num_dimensions, num_dimensions))\n",
        "for n in range(num_classes):\n",
        "  # クラス n に該当するデータ X_tmp\n",
        "  X_tmp = X[Y==n]\n",
        "  # クラス内平均\n",
        "  m = np.mean(X_tmp, axis=0)\n",
        "  cov_inner += np.dot((X_tmp-m).T, (X_tmp-m))\n",
        "\n",
        "# クラス間分散\n",
        "cov_intra = np.zeros((num_dimensions, num_dimensions))\n",
        "for n in range(num_classes):\n",
        "  # クラス n に該当するデータ X_tmp\n",
        "  X_tmp = X[Y==n]\n",
        "  # クラス n に該当するデータのサンプル数を得る\n",
        "  num_samples_n, num_dimensions = np.shape(X_tmp)\n",
        "  # クラス内平均\n",
        "  m = np.mean(X_tmp, axis=0)\n",
        "\n",
        "  # クラス間分散を計算\n",
        "  m_sub = m - m_all\n",
        "  m_sub = np.reshape(m_sub, (-1,1))\n",
        "  cov_intra += num_samples_n * np.dot(m_sub, m_sub.T)\n",
        "\n",
        "# クラス内分散-クラス間分散比行列\n",
        "J = np.dot(np.linalg.inv(cov_inner), cov_intra)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "続いてクラス内分散-クラス間分散比行列を固有値分解し，固有値が最も大きい固有ベクトル（第一固有ベクトル）を取り出します。"
      ],
      "metadata": {
        "id": "dGGd9LIjEoaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 固有値 eig_val と 固有ベクトル eig_vec を計算\n",
        "eig_val, eig_vec =np.linalg.eig(J)\n",
        "# データによっては固有値分解結果が複素数になる場合があるため，実部のみ取得\n",
        "eig_val = np.real(eig_val)\n",
        "eig_vec = np.real(eig_vec)\n",
        "\n",
        "# 固有値が最大となる固有ベクトルを取り出す\n",
        "max_id = np.argmax(eig_val)\n",
        "first_eig_vec = eig_vec[:, max_id]\n",
        "\n",
        "print(first_eig_vec)"
      ],
      "metadata": {
        "id": "dVgPsOtYMC7e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "第一固有ベクトルへ射影（内積を計算）し，その結果を散布図で描画します。  \n",
        "（ただし，散布図を書くにははx-yの2次元データが必要なのに対して，射影結果は1次元のスカラー値です。なので，y軸の値は常に0を入れることで，散布図を書いています。）"
      ],
      "metadata": {
        "id": "Paf4BLM9MchB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_lda = np.dot(X,first_eig_vec)\n",
        "\n",
        "plt.figure(figsize=(7,5))\n",
        "# x軸にはX_ldaの値を，y軸には0を入れて散布図を描画\n",
        "plt.scatter(X_lda[Y==0], np.zeros(np.size(X_lda[Y==0])), color='b', label='class 0')\n",
        "plt.scatter(X_lda[Y==1], np.zeros(np.size(X_lda[Y==1])), color='r', label='class 1')\n",
        "plt.xlabel('projection axis')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AhVP5pukTfwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "第一固有ベクトルへの射影により，クラス0とクラス1がうまく分離出来ていることが分かります。  \n",
        "実際に，X_ldaの値が正ならクラス1，負ならクラス0として2クラス分類を行い，分類正解率を測ってみます。  "
      ],
      "metadata": {
        "id": "-oK1i1_TNz05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 全ての要素がゼロのベクトルを用意\n",
        "Y_pred = np.zeros(num_samples, dtype=np.int64)\n",
        "# X_ldaが正なら Y_pradを1にする。\n",
        "Y_pred[X_lda > 0] = 1\n",
        "\n",
        "# 正解率を計算\n",
        "accuracy = 0\n",
        "for n in range(num_samples):\n",
        "  if Y_pred[n] == Y[n]:\n",
        "    # 分類結果と正解ラベルが一致していれば，正解数のカウントを1増やす\n",
        "    accuracy += 1\n",
        "accuracy = 100.0 * accuracy / num_samples\n",
        "\n",
        "print('Accuracy = %.3f' % (accuracy))"
      ],
      "metadata": {
        "id": "6bU91k8mOP_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "分類正解率が100%であることが分かりました。"
      ],
      "metadata": {
        "id": "1uQmcOPlPVTe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### クラスの境界を可視化する。\n",
        "上の処理では，第一固有ベクトルと内積を計算し，計算結果が正ならクラス1，0以下ならクラス0として2クラス分離していました。  \n",
        "よって，第一固有ベクトルを${\\bf w} = [w_1, w_2]$，データを${\\bf x} = [x_1, x_2]$とすると，  \n",
        "${\\bf w}{\\bf x}^{T} = w_1x_1 + w_2x_2 = 0$  \n",
        "がこの2クラスを分離する境界線ということになります。  \n",
        "この式を変形して  \n",
        "$x_2 = - w_1x_1 / w_2$  \n",
        "とすれば，この境界線を図示することができます。"
      ],
      "metadata": {
        "id": "DKykOGJQP32A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 境界線の作成\n",
        "x1 = np.linspace(-3,3) # -3から3へ一定間隔で増える等差数列\n",
        "x2 = -1.0 * first_eig_vec[0] * x1 / first_eig_vec[1]\n",
        "\n",
        "# プロット\n",
        "plt.figure(figsize=(7,7))\n",
        "plt.plot(x1, x2)\n",
        "plt.scatter(X[Y==0,0], X[Y==0,1], c='b', label='class0')\n",
        "plt.scatter(X[Y==1,0], X[Y==1,1], c='r', label='class1')\n",
        "plt.xlabel('x1')\n",
        "plt.ylabel('x2')\n",
        "plt.legend()\n",
        "plt.xlim([-3, 3])\n",
        "plt.ylim([-3, 3])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "V9OWtfj7Tvxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "これが線形判別分析によって導出された，2クラスの境界線です。"
      ],
      "metadata": {
        "id": "7TtlqhPcVOw7"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkdO-S8SuDPX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}