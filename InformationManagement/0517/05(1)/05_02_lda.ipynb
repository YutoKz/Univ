{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "05_02_lda.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbqkmaY9RA-z"
      },
      "source": [
        "# 第5回 その1: 線形判別分析\n",
        "3つのクラスの3教科テスト点数に対して線形判別分析を行ってみましょう。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "srIl-shURTM2"
      },
      "source": [
        "## ステップ0: Google Driveのマウントと作業フォルダへの移動  \n",
        "Google Drive に配置したデータを読み込むための準備です。  \n",
        "詳細については第二回の 02_01_graph.ipynb を参照してください。  \n",
        "\n",
        "ここでは\"マイドライブ/情報管理/05\"を作業フォルダとします。 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wf9ghfr_QzT1"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# フォルダの移動には\"%cd\"を使用します。\n",
        "# 作業フォルダへ移動\n",
        "%cd /content/drive/'My Drive'/情報管理/05/\n",
        "# 現在のフォルダの中身を表示\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNGpM3FYRiob"
      },
      "source": [
        "`sankyouka.csv`というデータが表示されていることを確認してください。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1DmeW6oRs8r"
      },
      "source": [
        "## ステップ1: データの読み込み\n",
        "まずは必要ライブラリをインポートします。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E4b4cfHPRXML"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wF6-hyJ2Sdau"
      },
      "source": [
        "`sankyouka.csv` を読み込みます。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkibCXvsRv-8"
      },
      "source": [
        "# pandas の関数 read_csv を用いた csvファイル読み込み\n",
        "csv_data = pd.read_csv('sankyouka.csv', encoding='SHIFT-JIS')\n",
        "# データの前半部(.headで取得できる)のみ表示\n",
        "display(csv_data.head())\n",
        "\n",
        "# numpy用データ(ndarray型) に変換する。\n",
        "X = csv_data.loc[:,'国語':].to_numpy()\n",
        "y = csv_data.loc[:,'クラス']\n",
        "\n",
        "# データのサンプル数と次元数を得る。\n",
        "(num_samples, num_dimensions) = np.shape(X)\n",
        "print('Information of scores (X)')\n",
        "print('  Nunber of samples: ' + str(num_samples))\n",
        "print('  Number of dimensions: ' + str(num_dimensions))\n",
        "\n",
        "# クラスの種類を得る。\n",
        "# unique(): pandasデータリストから，重複する数値を消す関数（[1,2,1,3,3,4] -> 重複数字を消して[1,2,3,4]となる）\n",
        "classes = y.unique()\n",
        "# クラス数を得る。\n",
        "num_classes = np.size(classes)\n",
        "\n",
        "print('Classes:' + str(classes))\n",
        "print('Number of classes: ' + str(num_classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSTsQodYTBS9"
      },
      "source": [
        "このデータは学生300名の3教科（国語，英語，数学）の得点を記録したものです。  \n",
        "得点情報は変数 `X` に格納されました。  \n",
        "よって`X`のサンプル数は300，次元数は3です。  \n",
        "\n",
        "また各学生は3種類のクラス（0, 1, 2）のどこかに属しています。  \n",
        "学生ごとのクラス番号は y に格納されました。  \n",
        "すなわち，クラス数 num_classes = 3 です。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdTDNHZFOpHG"
      },
      "source": [
        "3次元データなので，以下のようにして，一応プロットすることが可能です。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvYo1Q-2PRGU"
      },
      "source": [
        "color_set = ['b', 'r', 'g']\n",
        "\n",
        "from mpl_toolkits.mplot3d import axes3d\n",
        "from ipywidgets import interact\n",
        "\n",
        "def polyscatter(elevation):\n",
        "  fig = plt.figure(figsize=(8,8))\n",
        "  ax = fig.add_subplot(111, projection=\"3d\")\n",
        "  for n in range(num_classes):\n",
        "    ax.scatter(X[y==n,0], X[y==n,1], X[y==n,2], color=color_set[n], label='class: '+str(n))\n",
        "  ax.set_xlabel(\"Kokugo\")\n",
        "  ax.set_ylabel(\"Eigo\")\n",
        "  ax.set_zlabel(\"Suugaku\")\n",
        "  ax.view_init(elev=elevation)\n",
        "  plt.show()\n",
        "interact(polyscatter, elevation=(1, 90, 1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfwOQ7NLQcrn"
      },
      "source": [
        "図の上のバーを左右に動かすと，上下の角度が変えられます。  \n",
        "とは言え，ちょっと見づらいです。  \n",
        "次に，国語--英語，国語--数学，英語--数学 の3パターンで2次元プロットしてみます。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-8TwujnQ6eK"
      },
      "source": [
        "plt.figure(figsize=(18,5))\n",
        "plt.subplot(1,3,1)\n",
        "for n in range(num_classes):\n",
        "  plt.scatter(X[y==n,0], X[y==n,1], color=color_set[n], label='class: '+str(n))\n",
        "plt.xlabel('Kokugo')\n",
        "plt.ylabel('Eigo')\n",
        "plt.legend()\n",
        "plt.subplot(1,3,2)\n",
        "for n in range(num_classes):\n",
        "  plt.scatter(X[y==n,0], X[y==n,2], color=color_set[n], label='class: '+str(n))\n",
        "plt.xlabel('Kokugo')\n",
        "plt.ylabel('Suugaku')\n",
        "plt.legend()\n",
        "plt.subplot(1,3,3)\n",
        "for n in range(num_classes):\n",
        "  plt.scatter(X[y==n,1], X[y==n,2], color=color_set[n], label='class: '+str(n))\n",
        "plt.xlabel('Eigo')\n",
        "plt.ylabel('Suugaku')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igUMd4wBSekc"
      },
      "source": [
        "左の図を見ると，**クラス0（青）は英語に比べて国語が苦手のように見えます**。  \n",
        "また中央と右の図を見ると，**クラス2（緑）は数学が苦手のようです**。  \n",
        "\n",
        "以降，圧縮手法を使って分析していきます。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_z24qnO4qIu"
      },
      "source": [
        "## ステップ2: データの標準化\n",
        "主成分分析の時と同様に，分析の前処理としてデータの標準化を行います。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH8xw2-V4yn1"
      },
      "source": [
        "# 次元毎の平均と分散\n",
        "mu = np.mean(X, axis=0)\n",
        "std = np.std(X, axis=0)\n",
        "\n",
        "# 標準化\n",
        "X_norm = (X - mu) / std"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktlRCDquS7Jc"
      },
      "source": [
        "## ステップ3: 主成分分析を用いた場合 \n",
        "ためしに，主成分分析を使って3次元データを2次元データに圧縮してプロットしてみます。  \n",
        "主成分分析については05_01_pca.ipynbで解説しています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xR3GQ77JTJPp"
      },
      "source": [
        "# 分散共分散行列の計算\n",
        "# X.T とすることで転置してから cov に入力する点に注意\n",
        "cov = np.cov(X_norm.T, bias=True)\n",
        "\n",
        "# 固有値 eig_val と 固有ベクトル eig_vec を計算\n",
        "eig_val, eig_vec =np.linalg.eig(cov)\n",
        "# データによっては固有値分解結果が複素数になる場合があるため，実部のみ取得\n",
        "eig_val = np.real(eig_val)\n",
        "eig_vec = np.real(eig_vec)\n",
        "\n",
        "# 固有値を大きい順に並び替える\n",
        "order = np.argsort(eig_val)[::-1]\n",
        "eig_val = eig_val[order]\n",
        "eig_vec_pca = eig_vec[:,order]\n",
        "\n",
        "# 第二主成分までの固有ベクトルを用いて次元圧縮\n",
        "X_pca = np.dot(X_norm, eig_vec_pca[:,:2])\n",
        "\n",
        "# 二次元データのプロット\n",
        "color_set = ['b', 'r', 'g']\n",
        "plt.figure(figsize=(10,5))\n",
        "for n in range(num_classes):\n",
        "  plt.scatter(X_pca[y==n,0], X_pca[y==n,1], color=color_set[n], label='class: '+str(n))\n",
        "plt.xlabel('1st principal component')\n",
        "plt.ylabel('2nd principal component')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALvxSXfZT1eR"
      },
      "source": [
        "主成分分析を使って2次元にプロットした結果，クラス0（青）とクラス1（赤）が混ざってしまっていることが分かります。  \n",
        "主成分分析はあくまでデータ全体の分散を最大化するように2次元圧縮しており，各データのクラスについては一切考慮していないため，必ずしもクラスの違いが分かるような可視化がされません。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HSawEh5UZ-X"
      },
      "source": [
        "## ステップ4: 線形判別分析その1　クラス内分散とクラス間分散の計算\n",
        "では線形判別分析を行います。  \n",
        "そのための準備として，クラス内分散共分散行列`cov_inner`とクラス間分散共分散行列`cov_intra`を計算します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN9jvB8TT6ou"
      },
      "source": [
        "# クラス全体の平均\n",
        "m_all = np.mean(X_norm, axis=0)\n",
        "\n",
        "# クラス内分散共分散\n",
        "cov_inner = np.zeros((num_dimensions, num_dimensions))\n",
        "for n in range(num_classes):\n",
        "  # クラス n に該当するデータ X_tmp\n",
        "  X_tmp = X_norm[y==n]\n",
        "  # クラス内平均\n",
        "  m = np.mean(X_tmp, axis=0)\n",
        "  cov_inner += np.dot((X_tmp-m).T, (X_tmp-m))\n",
        "\n",
        "# クラス間分散\n",
        "cov_intra = np.zeros((num_dimensions, num_dimensions))\n",
        "for n in range(num_classes):\n",
        "  # クラス n に該当するデータ X_tmp\n",
        "  X_tmp = X_norm[y==n]\n",
        "  # クラス n に該当するデータのサンプル数を得る\n",
        "  num_samples_n, num_dimensions = np.shape(X_tmp)\n",
        "  # クラス内平均\n",
        "  m = np.mean(X_tmp, axis=0)\n",
        "\n",
        "  # クラス間分散を計算\n",
        "  m_sub = m - m_all\n",
        "  m_sub = np.reshape(m_sub, (-1,1))\n",
        "  cov_intra += num_samples_n * np.dot(m_sub, m_sub.T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFZcsyAtW8qo"
      },
      "source": [
        "## ステップ5: 線形判別分析その2: クラス内/間分散共分散比行列の固有値分解  \n",
        "クラス内分散の逆行列とクラス間分散の内積を計算し，計算結果に対して固有値分解を行います。  \n",
        "その後，固有値の大きい順に固有ベクトルを並べ替えます。  \n",
        "逆行列の計算には<font color=\"Red\"> **`linalg.inv`**</font> 関数を使用します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCwq-6jbR8D9"
      },
      "source": [
        "# クラス内分散-クラス間分散比行列\n",
        "J = np.dot(np.linalg.inv(cov_inner), cov_intra)\n",
        "\n",
        "# 固有値 eig_val と 固有ベクトル eig_vec を計算\n",
        "eig_val, eig_vec =np.linalg.eig(J)\n",
        "# データによっては固有値分解結果が複素数になる場合があるため，実部のみ取得\n",
        "eig_val = np.real(eig_val)\n",
        "eig_vec = np.real(eig_vec)\n",
        "\n",
        "# 固有値を大きい順に並び替える\n",
        "order = np.argsort(eig_val)[::-1]\n",
        "eig_val = eig_val[order]\n",
        "eig_vec_lda = eig_vec[:,order]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCPimpgMW8nO"
      },
      "source": [
        "## ステップ6: 線形判別分析その3: 次元圧縮とプロット\n",
        "第一および第二固有ベクトルを使って，データを二次元に圧縮します。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BN82w2qqSEp6"
      },
      "source": [
        "# 第二固有ベクトルまでとの内積を計算\n",
        "X_lda = np.dot(X_norm, eig_vec_lda[:,:2])\n",
        "\n",
        "# 二次元データのプロット\n",
        "color_set = ['b', 'r', 'g']\n",
        "plt.figure(figsize=(10,5))\n",
        "for n in range(num_classes):\n",
        "  plt.scatter(X_lda[y==n,0], X_lda[y==n,1], color=color_set[n], label='class: '+str(n))\n",
        "plt.xlabel('1st component')\n",
        "plt.ylabel('2nd component')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAZwhlEkZZDB"
      },
      "source": [
        "線形判別分析によって2次元圧縮した結果は，３つのクラスがきっちり分かれて分布していることが分かります。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcCdH0EUZGxs"
      },
      "source": [
        "## ステップ7: 考察  \n",
        "線形判別分析の固有ベクトルを見てみましょう。  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zshdgdbI8_i"
      },
      "source": [
        "print(eig_vec_lda[:,:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9bkNCUBZwI-"
      },
      "source": [
        "一つ目の軸（横軸）は「国語：-0.86，英語：0.48，数学：0.17」となっています。  \n",
        "国語が負の係数，英語が正の係数であることから，この軸では，英語が得意かつ国語が苦手なほど，正の方向に大きくなります。  \n",
        "そのため横軸上では，英語に比べて国語が苦手なクラス0（青）が，他のクラスから離れます。  \n",
        "\n",
        "二つ目の軸（縦軸）は「国語：0.44，英語：-0.49，数学：0.75」となっています。  \n",
        "特に数学に対する係数が大きいため，縦軸上では，数学で特に差が顕著なクラス1(赤)とクラス3(緑)が見分けやすくなっています。"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEsu3q3154t4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}